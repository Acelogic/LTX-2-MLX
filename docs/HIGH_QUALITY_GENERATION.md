# High-Quality Video Generation Guide

This guide covers the new high-quality generation features added to LTX-2-MLX, including two-stage pipeline and temporal upscaling.

## Overview

The high-quality generation features provide multiple approaches to improve video output:

1. **Two-Stage Pipeline**: Higher resolution with better semantic accuracy
2. **Temporal Upscaling**: Smoother motion (2x framerate)
3. **Improved Default Parameters**: Better CFG scale for semantic quality

## Quick Start

### Basic High-Quality Generation

```bash
python scripts/generate.py "A beautiful tropical beach with palm trees" \
    --height 480 --width 704 --frames 97 \
    --pipeline two-stage \
    --cfg 5.0 \
    --steps-stage1 15 \
    --fp16 \
    --output gens/hq_output.mp4
```

**Output:**
- Resolution: 960×1408 (2× spatial upscaling)
- Quality: Excellent
- Steps: 18 total (15 stage 1 + 3 stage 2)
- Memory: ~44GB

### Maximum Quality (Two-Stage + Temporal)

For the absolute best quality, combine two-stage generation with temporal upscaling:

```bash
# Step 1: Generate high-resolution base
python scripts/generate.py "A beautiful tropical beach with palm trees" \
    --height 480 --width 704 --frames 97 \
    --pipeline two-stage \
    --cfg 5.0 --steps-stage1 15 \
    --fp16 \
    --output gens/base.mp4

# Step 2: Apply temporal upscaling (separate to manage memory)
python scripts/upscale_temporal.py gens/base.mp4 \
    --output gens/smooth.mp4 \
    --weights weights/ltx-2/ltx-2-19b-distilled.safetensors \
    --temporal-weights weights/ltx-2/ltx-2-temporal-upscaler-x2-1.0.safetensors \
    --fp16
```

**Final Output:**
- Resolution: 960×1408
- Frames: 193 (2× framerate)
- Framerate: 16 fps
- Quality: Maximum
- Memory: Sequential execution (44GB + 15GB)

---

## Two-Stage Pipeline

### How It Works

The two-stage pipeline combines the quality of CFG guidance with the speed of distilled refinement:

**Stage 1: CFG Generation at Half Resolution**
- Generates at 50% resolution (e.g., 240×352 for 480×704 target)
- Uses LTX2Scheduler with classifier-free guidance
- Default: 15 steps with CFG scale 5.0
- Produces high-quality latents with strong text adherence

**Stage 2: Spatial Upscaling + Distilled Refinement**
- Applies 2× spatial upscaler (240×352 → 480×704)
- Refines at full resolution using distilled model
- Default: 3 fast steps without CFG
- Final output at 2× target resolution (960×1408)

### Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `--pipeline two-stage` | Enable two-stage pipeline | N/A |
| `--steps-stage1` | CFG steps for stage 1 | 15 |
| `--steps-stage2` | Refinement steps for stage 2 | 3 |
| `--cfg-stage1` | CFG scale for stage 1 | Uses `--cfg` value |
| `--cfg` | Overall CFG scale | 5.0 |
| `--spatial-upscaler-weights` | Path to spatial upscaler | Required |

### Requirements

- **Weights**: `ltx-2-spatial-upscaler-x2-1.0.safetensors` (950MB)
- **Memory**: ~44GB (fits in 32-64GB systems with FP16)
- **Time**: ~5-10 minutes for 97 frames @ 480×704 on M3 Max

### Examples

**High-Quality 480×704 → 960×1408:**
```bash
python scripts/generate.py "A red sports car driving on a highway at sunset" \
    --height 480 --width 704 --frames 97 \
    --pipeline two-stage \
    --cfg 5.0 --steps-stage1 15 \
    --fp16 \
    --weights weights/ltx-2/ltx-2-19b-distilled.safetensors \
    --spatial-upscaler-weights weights/ltx-2/ltx-2-spatial-upscaler-x2-1.0.safetensors \
    --output gens/sunset_car_hq.mp4
```

**Faster Lower-Resolution (256×384 → 512×768):**
```bash
python scripts/generate.py "A blue ball bouncing on green grass" \
    --height 256 --width 384 --frames 33 \
    --pipeline two-stage \
    --cfg 5.0 --steps-stage1 10 \
    --fp16 \
    --output gens/bouncing_ball.mp4
```

**Maximum Quality with Dev Model:**
```bash
python scripts/generate.py "A cat walking through a garden" \
    --height 480 --width 704 --frames 97 \
    --pipeline two-stage \
    --model-variant dev \
    --cfg 7.0 --steps-stage1 25 \
    --fp16 \
    --output gens/cat_garden_dev.mp4
```

---

## Temporal Upscaling

### Overview

The temporal upscaling script applies 2× framerate interpolation to existing videos, doubling the number of frames for smoother motion.

### Usage

```bash
python scripts/upscale_temporal.py <input_video> \
    --output <output_video> \
    --weights <ltx2_weights> \
    --temporal-weights <temporal_upscaler_weights> \
    --fp16
```

### Example

```bash
python scripts/upscale_temporal.py gens/hq_beach.mp4 \
    --output gens/hq_beach_smooth.mp4 \
    --weights weights/ltx-2/ltx-2-19b-distilled.safetensors \
    --temporal-weights weights/ltx-2/ltx-2-temporal-upscaler-x2-1.0.safetensors \
    --fp16
```

**Input:** 97 frames @ 8fps
**Output:** 193 frames @ 16fps (2× smoother)

### Requirements

- **Weights**: `ltx-2-temporal-upscaler-x2-1.0.safetensors` (250MB)
- **Memory**: ~15GB (VAE encoder + upscaler + decoder)
- **Input**: Any video generated by LTX-2-MLX

---

## Improved Default Parameters

### CFG Scale: 3.0 → 5.0

The default classifier-free guidance scale has been increased from 3.0 to 5.0 for better semantic accuracy and text adherence.

**Benefits:**
- Stronger text conditioning
- Better prompt adherence (palm trees, sunsets, specific colors)
- More coherent semantic content

**Trade-off:**
- Slightly longer generation time (minimal with distilled model)
- May over-saturate colors (use `--guidance-rescale 0.7` to mitigate)

**Override if needed:**
```bash
# Lower CFG for more variation
--cfg 3.0

# Higher CFG for stronger text adherence
--cfg 7.0
```

---

## Quality Comparison

| Approach | Resolution | Frames | Steps | CFG | Memory | Time (M3 Max) | Quality |
|----------|-----------|--------|-------|-----|--------|---------------|---------|
| **Distilled (current)** | 480×704 | 97 | 8 | 5.0 | ~30GB | ~3 min | Good |
| **Two-Stage** | 960×1408 | 97 | 18 | 5.0 | ~44GB | ~8 min | Excellent |
| **+ Temporal** | 960×1408 | 193 | 18+sep | 5.0 | ~59GB (seq) | ~12 min | Maximum |
| **Dev Model** | 480×704 | 97 | 30 | 7.0 | ~40GB | ~10 min | Excellent |

---

## Memory Management

### Why Sequential Execution?

Running two-stage + temporal simultaneously would require ~59GB:
```
Gemma 3 (FP16):        12GB
Transformer (FP16):    19GB
VAE Encoder/Decoder:    4GB
Spatial Upscaler:       3GB
Temporal Upscaler:      3GB
Working memory:        18GB
-------------------------
Total:                 59GB
```

By running temporal upscaling separately, we stay within memory constraints:
- **Two-Stage Only**: ~44GB (fits in 64GB systems)
- **Temporal Only**: ~15GB (easily fits)

### Memory Optimization Tips

1. **Use FP16**: Always pass `--fp16` flag (~50% memory reduction)
2. **Reduce Resolution**: Start with 256×384 for testing
3. **Fewer Frames**: Use 33 or 49 frames instead of 97
4. **Reduce Steps**: 10-12 steps for stage 1 still gives good results

---

## Troubleshooting

### "Two-stage pipeline requires --spatial-upscaler-weights"

You need to specify the spatial upscaler weights:
```bash
--spatial-upscaler-weights weights/ltx-2/ltx-2-spatial-upscaler-x2-1.0.safetensors
```

Download from HuggingFace if not available:
```bash
# From Lightricks/LTX-2 repository
wget https://huggingface.co/Lightricks/LTX-2/resolve/main/ltx-2-spatial-upscaler-x2-1.0.safetensors \
    -O weights/ltx-2/ltx-2-spatial-upscaler-x2-1.0.safetensors
```

### "Two-stage pipeline does not support audio generation mode"

The two-stage pipeline is currently video-only. Remove the `--generate-audio` flag or use `--pipeline text-to-video` instead.

### Out of Memory

Try these solutions:
1. Enable FP16: `--fp16`
2. Reduce resolution: `--height 384 --width 576`
3. Fewer frames: `--frames 33`
4. Lower stage 1 steps: `--steps-stage1 10`

### Low Quality Output

Increase quality settings:
1. More steps: `--steps-stage1 20`
2. Higher CFG: `--cfg 6.0` or `--cfg 7.0`
3. Use dev model: `--model-variant dev`

---

## Implementation Details

### Files Modified

1. **`scripts/generate.py`**
   - Added `--steps-stage1`, `--steps-stage2`, `--cfg-stage1` parameters
   - Changed default CFG from 3.0 to 5.0
   - Integrated TwoStagePipeline class
   - Added validation for two-stage requirements

2. **`scripts/upscale_temporal.py`** (NEW)
   - Standalone temporal upscaling script
   - Encode → upsample → decode pipeline
   - 16fps output for 2× framerate

3. **`LTX_2_MLX/pipelines/two_stage.py`**
   - Two-stage pipeline implementation
   - Stage 1: CFG at half resolution
   - Stage 2: Spatial upscale + distilled refinement

### Architecture

```
┌─────────────────────────────────────────────────┐
│              Two-Stage Pipeline                  │
├─────────────────────────────────────────────────┤
│  Stage 1: CFG Generation (Half Resolution)      │
│  ┌───────────────────────────────────────────┐  │
│  │  Input: Text embeddings                   │  │
│  │  Resolution: height//2 × width//2         │  │
│  │  Steps: 15 (default)                      │  │
│  │  CFG: 5.0 (default)                       │  │
│  │  Scheduler: LTX2Scheduler                 │  │
│  │  Output: Latent @ half resolution         │  │
│  └───────────────────────────────────────────┘  │
│                      ↓                           │
│  Spatial Upscaler: 2× resolution                │
│                      ↓                           │
│  Stage 2: Distilled Refinement (Full Res)      │
│  ┌───────────────────────────────────────────┐  │
│  │  Input: Upscaled latent                   │  │
│  │  Resolution: height × width               │  │
│  │  Steps: 3 (fast)                          │  │
│  │  CFG: None (distilled)                    │  │
│  │  Scheduler: Distilled sigmas              │  │
│  │  Output: Latent @ full resolution         │  │
│  └───────────────────────────────────────────┘  │
│                      ↓                           │
│  VAE Decoder → Video @ 2× target resolution     │
└─────────────────────────────────────────────────┘
```

---

## Future Improvements

Potential enhancements for even higher quality:

1. **Image-to-Video with Two-Stage**: Conditioning on keyframe images
2. **LoRA Support**: Custom style transfer with two-stage
3. **Dynamic Step Scheduling**: Adaptive steps based on content complexity
4. **Memory-Efficient Mode**: Tiled processing for 4K generation
5. **Single-Pass Temporal**: Integrated temporal upscaling without separate encoding

---

## References

- [LTX-2 Paper](https://arxiv.org/abs/2501.00103)
- [LTX-2 GitHub](https://github.com/Lightricks/LTX-2)
- [Architecture Documentation](LTX-2-ARCHITECTURE.md)
- [Porting Guide](PORTING.md)
